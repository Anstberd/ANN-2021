{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f74090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1977317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911d00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "\n",
    "raw_text = open(filename).read()\n",
    "\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d457c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51e43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  462145\n",
      "Total Vocab:  90\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "\n",
    "n_vocab = len(chars)\n",
    "\n",
    "print (\"Total Characters: \", n_chars)\n",
    "\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8ff509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  462045\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "dataX = []\n",
    "\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213252d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b83ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86706904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class print_callback(Callback):\n",
    "    def __init__(self, data, int_to_char, dist):\n",
    "        self.data = data\n",
    "        self.int_to_char = int_to_char\n",
    "        self.dist = dist \n",
    "    def gen_text(self, size=100):\n",
    "        start = np.random.randint(0, n_patterns-1)\n",
    "        pattern = self.data[start]\n",
    "        text = []\n",
    "        for i in range(size):\n",
    "            x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "            x = x / float(n_vocab)\n",
    "            prediction = model.predict(x, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            result = self.int_to_char[index]\n",
    "            text.append(result)\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:len(pattern)]\n",
    "        return \"\".join(text)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.dist == 0 or epoch == self.params[\"epochs\"] - 1:\n",
    "          print(f'epoch {epoch}/{self.params[\"epochs\"]}:')\n",
    "          gen = self.gen_text(200)\n",
    "          print('Generated text: ', gen, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662754c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c48b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, print_callback(dataX, int_to_char, 5), TensorBoard(log_dir='logs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c6e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 3.1398\n",
      "Epoch 00001: loss improved from inf to 3.13979, saving model to weights-improvement-01-3.1398.hdf5\n",
      "epoch 0/20:\n",
      "Generated text: что сылоран верао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ваоао ва\n",
      "462045/462045 [==============================] - 521s 1ms/sample - loss: 3.1398\n",
      "Epoch 2/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 3.0330\n",
      "Epoch 00002: loss improved from 3.13979 to 3.03301, saving model to weights-improvement-02-3.0330.hdf5\n",
      "462045/462045 [==============================] - 505s 1ms/sample - loss: 3.0330\n",
      "Epoch 3/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.9122\n",
      "Epoch 00003: loss improved from 3.03301 to 2.91212, saving model to weights-improvement-03-2.9121.hdf5\n",
      "462045/462045 [==============================] - 509s 1ms/sample - loss: 2.9121\n",
      "Epoch 4/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.7146\n",
      "Epoch 00004: loss improved from 2.91212 to 2.71458, saving model to weights-improvement-04-2.7146.hdf5\n",
      "462045/462045 [==============================] - 503s 1ms/sample - loss: 2.7146\n",
      "Epoch 5/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.5179\n",
      "Epoch 00005: loss improved from 2.71458 to 2.51789, saving model to weights-improvement-05-2.5179.hdf5\n",
      "462045/462045 [==============================] - 505s 1ms/sample - loss: 2.5179\n",
      "Epoch 6/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.3883\n",
      "Epoch 00006: loss improved from 2.51789 to 2.38829, saving model to weights-improvement-06-2.3883.hdf5\n",
      "epoch 5/20:\n",
      "Generated text: оооан мераниз волтоида  что выла зашита в сорро сераси востренностей : саразити сереоааит саризитн сераоити сиртома  что выла зашита в сорро сераси востренностей : саразити сереоааит саризитн сераоити\n",
      "462045/462045 [==============================] - 521s 1ms/sample - loss: 2.3883\n",
      "Epoch 7/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.2908\n",
      "Epoch 00007: loss improved from 2.38829 to 2.29082, saving model to weights-improvement-07-2.2908.hdf5\n",
      "462045/462045 [==============================] - 505s 1ms/sample - loss: 2.2908\n",
      "Epoch 8/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.2170\n",
      "Epoch 00008: loss improved from 2.29082 to 2.21705, saving model to weights-improvement-08-2.2171.hdf5\n",
      "462045/462045 [==============================] - 522s 1ms/sample - loss: 2.2171\n",
      "Epoch 9/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.1571\n",
      "Epoch 00009: loss improved from 2.21705 to 2.15711, saving model to weights-improvement-09-2.1571.hdf5\n",
      "462045/462045 [==============================] - 501s 1ms/sample - loss: 2.1571\n",
      "Epoch 10/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.1069\n",
      "Epoch 00010: loss improved from 2.15711 to 2.10684, saving model to weights-improvement-10-2.1068.hdf5\n",
      "462045/462045 [==============================] - 502s 1ms/sample - loss: 2.1068\n",
      "Epoch 11/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.0664\n",
      "Epoch 00011: loss improved from 2.10684 to 2.06640, saving model to weights-improvement-11-2.0664.hdf5\n",
      "epoch 10/20:\n",
      "Generated text: раний система  что сазвуплощённ в сереоан сереоание сеая /что пазауплощения терослнази сероолаиин  что сазвуплощённ в сереоан сереоание сеая /что пазауплощения терослнази сероолаиин  что сазвуплощённ \n",
      "462045/462045 [==============================] - 512s 1ms/sample - loss: 2.0664\n",
      "Epoch 12/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 2.0310\n",
      "Epoch 00012: loss improved from 2.06640 to 2.03104, saving model to weights-improvement-12-2.0310.hdf5\n",
      "462045/462045 [==============================] - 502s 1ms/sample - loss: 2.0310\n",
      "Epoch 13/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.9993\n",
      "Epoch 00013: loss improved from 2.03104 to 1.99927, saving model to weights-improvement-13-1.9993.hdf5\n",
      "462045/462045 [==============================] - 501s 1ms/sample - loss: 1.9993\n",
      "Epoch 14/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.9731\n",
      "Epoch 00014: loss improved from 1.99927 to 1.97307, saving model to weights-improvement-14-1.9731.hdf5\n",
      "462045/462045 [==============================] - 501s 1ms/sample - loss: 1.9731\n",
      "Epoch 15/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.9470\n",
      "Epoch 00015: loss improved from 1.97307 to 1.94693, saving model to weights-improvement-15-1.9469.hdf5\n",
      "462045/462045 [==============================] - 502s 1ms/sample - loss: 1.9469\n",
      "Epoch 16/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.9302\n",
      "Epoch 00016: loss improved from 1.94693 to 1.93015, saving model to weights-improvement-16-1.9301.hdf5\n",
      "epoch 15/20:\n",
      "Generated text: штар в посеое паразитиого дрона  что выл зашит в соирос кркусственного солнца  что выл зашит в соирос кркусственного солнца  что выл зашит в соирос кркусственного солнца  что выл зашит в соирос кркусс\n",
      "462045/462045 [==============================] - 512s 1ms/sample - loss: 1.9301\n",
      "Epoch 17/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.9065\n",
      "Epoch 00017: loss improved from 1.93015 to 1.90656, saving model to weights-improvement-17-1.9066.hdf5\n",
      "462045/462045 [==============================] - 507s 1ms/sample - loss: 1.9066\n",
      "Epoch 18/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.8899\n",
      "Epoch 00018: loss improved from 1.90656 to 1.88988, saving model to weights-improvement-18-1.8899.hdf5\n",
      "462045/462045 [==============================] - 508s 1ms/sample - loss: 1.8899\n",
      "Epoch 19/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.8734\n",
      "Epoch 00019: loss improved from 1.88988 to 1.87337, saving model to weights-improvement-19-1.8734.hdf5\n",
      "462045/462045 [==============================] - 510s 1ms/sample - loss: 1.8734\n",
      "Epoch 20/20\n",
      "461952/462045 [============================>.] - ETA: 0s - loss: 1.8586\n",
      "Epoch 00020: loss improved from 1.87337 to 1.85856, saving model to weights-improvement-20-1.8586.hdf5\n",
      "epoch 19/20:\n",
      "Generated text: шинной природы коога тропояотя г мосгрооно колго кроуа сарроостриняется в соанм лоова проооколо в мосгоро поотороло валаит вироральной сереооноо сеая  что был зашит в сереорное селесные жидкости  что \n",
      "462045/462045 [==============================] - 521s 1ms/sample - loss: 1.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db47584a88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab74ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7020), started 0:03:32 ago. (Use '!kill 7020' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1db4860ddc8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9cbb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 7020: No such process\n"
     ]
    }
   ],
   "source": [
    "!kill 7020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662bbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
